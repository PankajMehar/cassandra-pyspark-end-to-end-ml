{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pytz\n",
    "import traceback\n",
    "import time_uuid\n",
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Cassandra and loading data into Pyspark's Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf = SparkConf()\\\n",
    "    .setAppName(APPNAME)\\\n",
    "    .setMaster(MASTER)\\\n",
    "    .set(\"spark.cassandra.connection.host\", CASSANDRA_HOST)\\\n",
    "    .set(\"spark.cassandra.connection.port\", CASSANDRA_PORT)\\\n",
    "    .set(\"spark.cassandra.auth.username\", CASSANDRA_USERNAME)\\\n",
    "    .set(\"spark.cassandra.auth.password\", CASSANDRA_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkContext(MASTER, APPNAME, conf=conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "sqlContext.sql(\"\"\"CREATE TEMPORARY TABLE %s \\\n",
    "                  USING org.apache.spark.sql.cassandra \\\n",
    "                  OPTIONS ( table \"%s\", \\\n",
    "                            keyspace \"%s\", \\\n",
    "                            cluster \"Test Cluster\", \\\n",
    "                            pushdown \"true\") \\\n",
    "              \"\"\" % (TABLE_QUERYABLE, TABLE_QUERYABLE, KEYSPACE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier as RF\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, VectorAssembler, SQLTransformer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import numpy as np\n",
    "import random\n",
    "import functools\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import RandomForest, RandomForestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are loading data from Cassandra and use existing saved model to predict values (online model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bucket_id', 'string'),\n",
       " ('unix_timestamp', 'bigint'),\n",
       " ('age', 'int'),\n",
       " ('city', 'string'),\n",
       " ('created_at', 'timestamp'),\n",
       " ('email', 'string'),\n",
       " ('event_id', 'string'),\n",
       " ('event_name', 'string'),\n",
       " ('gender', 'string'),\n",
       " ('job', 'string'),\n",
       " ('name', 'string'),\n",
       " ('zipcode', 'string')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableData = sqlContext.sql(\"SELECT * FROM %s\" % (TABLE_QUERYABLE))\n",
    "tableData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_select = ['age', 'city', 'email', 'gender', 'job', 'zipcode']\n",
    "df = tableData.select(cols_select).dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll have to do feature engineering and label encoding on this data as well. As the model accepts only labeled data of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding user behavior (POSITIVE, NOT-POSITIVE) randomly as our data is randomly generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def func(d):\n",
    "    p = {}\n",
    "    for x in d:\n",
    "        p['age'] = d.age\n",
    "        p['city'] = d.city\n",
    "        p['email'] = d.email\n",
    "        p['gender'] = d.gender\n",
    "        p['job'] = d.job\n",
    "        p['zipcode'] = d.zipcode\n",
    "    p['behaviour'] = str(random.choice(['POSITIVE', 'NEGATIVE']))\n",
    "    return p\n",
    "\n",
    "features = df.map(lambda x: func(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing label encoding on the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "def labelForAge(s):\n",
    "    s = int(s)\n",
    "    if s <= 20:\n",
    "        return 0.0\n",
    "    elif s > 20 and s <= 40:\n",
    "        return 1.0\n",
    "    elif s > 40 and s <= 50:\n",
    "        return 2.0\n",
    "    elif s > 50 and s <= 60:\n",
    "        return 3.0\n",
    "    else:\n",
    "        return -1.0\n",
    "\n",
    "def labelForCity(s):\n",
    "    if len(s) <= 8:\n",
    "        return 0.0\n",
    "    elif s > 8 and s <= 10:\n",
    "        return 1.0\n",
    "    elif s > 10 and s <= 14:\n",
    "        return 2.0\n",
    "    elif s > 14 and s <= 20:\n",
    "        return 3.0\n",
    "    else:\n",
    "        return -1.0\n",
    "\n",
    "def labelForEmail(s):\n",
    "    if len(s) <= 5:\n",
    "        return 0.0\n",
    "    elif s > 5 and s <= 7:\n",
    "        return 1.0\n",
    "    elif s > 7 and s <= 9:\n",
    "        return 2.0\n",
    "    elif s > 9 and s <= 12:\n",
    "        return 3.0\n",
    "    else:\n",
    "        return -1.0\n",
    "\n",
    "def labelForGender(s):\n",
    "    if s == 'M':\n",
    "        return 0.0\n",
    "    elif s == 'F':\n",
    "        return 1.0\n",
    "    else:\n",
    "        return -1.0\n",
    "    \n",
    "def labelForJob(s):\n",
    "    s = s.lower()\n",
    "    if 'engineer' in s:\n",
    "        return 0.0\n",
    "    elif 'architect' in s:\n",
    "        return 1.0\n",
    "    elif 'analyst' in s:\n",
    "        return 2.0\n",
    "    elif 'designer' in s:\n",
    "        return 3.0\n",
    "    elif 'officer' in s:\n",
    "        return 4.0\n",
    "    elif 'teacher' in s:\n",
    "        return 5.0\n",
    "    elif 'it' in s:\n",
    "        return 6.0\n",
    "    else:\n",
    "        return -1.0   \n",
    "\n",
    "def labelForZipcode(s):\n",
    "    s = int(s)\n",
    "    if s <= 10000:\n",
    "        return 0.0\n",
    "    elif s > 10000 and s <= 30000:\n",
    "        return 1.0\n",
    "    elif s > 30000 and s <= 50000:\n",
    "        return 2.0\n",
    "    elif s > 50000 and s <= 70000:\n",
    "        return 3.0\n",
    "    elif s > 70000 and s <= 90000:\n",
    "        return 4.0\n",
    "    elif s > 90000:\n",
    "        return 5.0\n",
    "    else:\n",
    "        return -1.0\n",
    "\n",
    "label_Age = UserDefinedFunction(labelForAge, DoubleType())\n",
    "label_City = UserDefinedFunction(labelForCity, DoubleType())\n",
    "label_Email = UserDefinedFunction(labelForEmail, DoubleType())\n",
    "label_Gender = UserDefinedFunction(labelForGender, DoubleType())\n",
    "label_Job = UserDefinedFunction(labelForJob, DoubleType())\n",
    "label_Zipcode = UserDefinedFunction(labelForZipcode, DoubleType())\n",
    "\n",
    "features_df = features.toDF()\n",
    "labeledData = features_df.select(label_Age(features_df.age).alias('age_label'),\\\n",
    "                              label_City(features_df.city).alias('city_label'),\\\n",
    "                              label_Email(features_df.email).alias('email_label'),\\\n",
    "                              label_Gender(features_df.gender).alias('gender_label'),\\\n",
    "                              label_Job(features_df.job).alias('job_label'),\\\n",
    "                              label_Zipcode(features_df.zipcode).alias('zipcode_label'),\\\n",
    "                              features_df.behaviour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_new = ['age_label', 'city_label', 'email_label', 'gender_label', 'job_label', 'zipcode_label']\n",
    "assembler_features = VectorAssembler(inputCols=cols_new, outputCol='features')\n",
    "labelIndexer = StringIndexer(inputCol='behaviour', outputCol=\"label\")\n",
    "tmp = [assembler_features, labelIndexer]\n",
    "pipeline = Pipeline(stages=tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Distribution of Pos and Neg in data is: ', [Row(label=1.0, count=51014), Row(label=0.0, count=48996)])\n"
     ]
    }
   ],
   "source": [
    "allData = pipeline.fit(labeledData).transform(labeledData)\n",
    "allData.cache()\n",
    "print(\"Distribution of Pos and Neg in data is: \", allData.groupBy(\"label\").count().take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the model we had saved from offline process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeModel.load(sc, \"my_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'DecisionTreeModel classifier of depth 5 with 61 nodes\\n  If (feature 0 <= 0.0)\\n   If (feature 1 <= -1.0)\\n    If (feature 4 <= -1.0)\\n     If (feature 5 <= 0.0)\\n      If (feature 3 <= 0.0)\\n       Predict: 0.0\\n      Else (feature 3 > 0.0)\\n       Predict: 1.0\\n     Else (feature 5 > 0.0)\\n      If (feature 5 <= 2.0)\\n       Predict: 1.0\\n      Else (feature 5 > 2.0)\\n       Predict: 1.0\\n    Else (feature 4 > -1.0)\\n     If (feature 3 <= 0.0)\\n      If (feature 5 <= 4.0)\\n       Predict: 1.0\\n      Else (feature 5 > 4.0)\\n       Predict: 0.0\\n     Else (feature 3 > 0.0)\\n      If (feature 5 <= 4.0)\\n       Predict: 0.0\\n      Else (feature 5 > 4.0)\\n       Predict: 1.0\\n   Else (feature 1 > -1.0)\\n    If (feature 5 <= 4.0)\\n     If (feature 5 <= 2.0)\\n      If (feature 3 <= 0.0)\\n       Predict: 0.0\\n      Else (feature 3 > 0.0)\\n       Predict: 1.0\\n     Else (feature 5 > 2.0)\\n      If (feature 5 <= 3.0)\\n       Predict: 0.0\\n      Else (feature 5 > 3.0)\\n       Predict: 0.0\\n    Else (feature 5 > 4.0)\\n     If (feature 4 <= 4.0)\\n      If (feature 3 <= 0.0)\\n       Predict: 1.0\\n      Else (feature 3 > 0.0)\\n       Predict: 0.0\\n     Else (feature 4 > 4.0)\\n      Predict: 0.0\\n  Else (feature 0 > 0.0)\\n   If (feature 0 <= 1.0)\\n    If (feature 4 <= 5.0)\\n     If (feature 4 <= 3.0)\\n      If (feature 5 <= 1.0)\\n       Predict: 0.0\\n      Else (feature 5 > 1.0)\\n       Predict: 0.0\\n     Else (feature 4 > 3.0)\\n      If (feature 1 <= -1.0)\\n       Predict: 1.0\\n      Else (feature 1 > -1.0)\\n       Predict: 0.0\\n    Else (feature 4 > 5.0)\\n     If (feature 5 <= 0.0)\\n      If (feature 3 <= 0.0)\\n       Predict: 1.0\\n      Else (feature 3 > 0.0)\\n       Predict: 1.0\\n     Else (feature 5 > 0.0)\\n      If (feature 3 <= 0.0)\\n       Predict: 0.0\\n      Else (feature 3 > 0.0)\\n       Predict: 0.0\\n   Else (feature 0 > 1.0)\\n    If (feature 0 <= 2.0)\\n     If (feature 3 <= 0.0)\\n      If (feature 4 <= 4.0)\\n       Predict: 0.0\\n      Else (feature 4 > 4.0)\\n       Predict: 1.0\\n     Else (feature 3 > 0.0)\\n      If (feature 4 <= -1.0)\\n       Predict: 1.0\\n      Else (feature 4 > -1.0)\\n       Predict: 0.0\\n    Else (feature 0 > 2.0)\\n     If (feature 3 <= 0.0)\\n      If (feature 4 <= 5.0)\\n       Predict: 1.0\\n      Else (feature 4 > 5.0)\\n       Predict: 0.0\\n     Else (feature 3 > 0.0)\\n      If (feature 4 <= 1.0)\\n       Predict: 0.0\\n      Else (feature 4 > 1.0)\\n       Predict: 1.0\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(allData.map(lambda x: x.features))\n",
    "labelsAndPredictions = allData.map(lambda lp: lp.label).zip(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (1.0, 0.0),\n",
       " (1.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 0.0),\n",
       " (1.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 0.0),\n",
       " (1.0, 0.0),\n",
       " (1.0, 1.0),\n",
       " (0.0, 1.0)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsAndPredictions.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
